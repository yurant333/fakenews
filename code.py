# -*- coding: utf-8 -*-
"""Test task.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gRmxdJ9D5pkf5mRJO_aMhW9MFALUecc7

Импортируем данные по задаче
"""

# Скачивание файла (подставить свою ссылку)
!wget -O "nlp_test_task_2022.zip" "https://disk.skbkontur.ru/index.php/s/aknGb6oZSzA8djG/download"
# Распаковка архива
!unzip "nlp_test_task_2022.zip"

"""Данные из тренировочных данных помещаем в переменную"""

# Подключаем Pandas
import pandas as pd
# Считываем таблицу в переменную
df = pd.read_table('dataset/train.tsv',)
# Выведем информацию о значениях для проверки отстутствия значений NULL
df.info()

"""Зададим фичи, цель и разделим данные"""

# Импортируем модуль из skilit-learn для разделения данных
from sklearn.model_selection import train_test_split
# Зададим фичи и цель
X = df['title']
y = df['is_fake']
# Разделяем на тестовые и тренировочные данные
X_train, X_test, y_train, y_test = train_test_split(X, y)

"""Создадим список стоп слов"""

# Загрузим стороннюю базу стоп слов из nltk, так как в skilit-learn нет списка русских слов
!pip install -q wordcloud
import wordcloud
import nltk
nltk.download('stopwords')
# Cоздадим список стоп слов
stopwords = nltk.corpus.stopwords.words('russian')

"""Выполним векторизацию, трансформацию и предварительную классификацию через несколько методов, затем по наибольшему количеству F1 score выберим лучший метод"""

# Импортируем необходимые модули и методы
# Импортируем метод векторизации из skilit-learn
from sklearn.feature_extraction.text import CountVectorizer
# Импортируем метод трансформации из skilit-learn
from sklearn.feature_extraction.text import TfidfTransformer
# Импортируем пайплайн из skilit-learn
from sklearn.pipeline import Pipeline
# Импортируем популярные методы классификации из skilit-learn
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.linear_model import SGDClassifier
# Импортируем модуль из skilit-learn для оценки
from sklearn.metrics import f1_score

# Создадим пайплайны для MultinomialNB, PassiveAggressiveClassifier, SGDClassifier
plp_text_predprocessing_mnb = Pipeline([('vect', CountVectorizer(stop_words=stopwords)),
                                        ('tfidf', TfidfTransformer()),
                                        ('mnb', MultinomialNB()),
                                        ])

plp_text_predprocessing_pac = Pipeline([('vect', CountVectorizer(stop_words=stopwords)),
                                        ('tfidf', TfidfTransformer()),
                                        ('pac', PassiveAggressiveClassifier()),
                                        ])

plp_text_predprocessing_sgd = Pipeline([('vect', CountVectorizer(stop_words=stopwords)),
                                        ('tfidf', TfidfTransformer()),
                                        ('sgd', SGDClassifier()),
                                        ])
# Создадим список пайплайнов
plp_list = [plp_text_predprocessing_mnb, plp_text_predprocessing_pac, plp_text_predprocessing_sgd]
# Прогоним классификацию и выберем лучший метод
for plp in plp_list:
  plp.fit(X_train, y_train)
  y_pred_plp = plp.predict(X_test)
  print('F1 score: %f' % (f1_score(y_test, y_pred_plp)))

"""Лучшую классфикацию показал MultinomialNB, тюнинганем его и прогоним на кросвалидированных данных"""

# Импортируем необходимые модули и методы
from sklearn.model_selection import GridSearchCV
import numpy as np

# Создадим пайплайны для MultinomialNB
plp_text_tuning = Pipeline([('vect', CountVectorizer(stop_words=stopwords)),
                      ('tfidf', TfidfTransformer()),
                      ('mnb', MultinomialNB()),
 ])

# Зададим параметры для грид сетки
tuning_parameters = {
    'vect__max_df': np.linspace(0.1, 1, 4),
    'tfidf__norm': ['l1', 'l2'],
    'tfidf__use_idf': [True, False],
    'tfidf__smooth_idf': [True, False],
    'tfidf__sublinear_tf': [True, False],
    'mnb__alpha': np.linspace(0.1, 2, 5),
    'mnb__fit_prior': [True, False]
}

# Созадим экземпляр класса GridSearchCV
grid_tuning = GridSearchCV(plp_text_tuning, cv=5, param_grid=tuning_parameters)
# Делаем подгонку
grid_tuning.fit(X_train, y_train)
# Выведем лучшую оценку и параметры
print('Best: %f using %s' % (grid_tuning.best_score_, 
    grid_tuning.best_params_))

"""
Поиск лучших параметров был выполнен не быстро, сохраним их для возможного использования
Best: 0.830247 using {'mnb__alpha': 0.575, 'mnb__fit_prior': False, 'tfidf__norm': 'l2', 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': True, 'vect__max_df': 0.1}
"""

"""Создадим финальный пайплайн и выполним классфикацию тюнингованной модели"""

# Создади финальный пайплайн
plp_final = Pipeline([('vect', CountVectorizer(stop_words=stopwords)),
                                    ('tfidf', TfidfTransformer()),
                                    ('mnb', MultinomialNB()),
                                    ])
# Зададим параметры для тюнингованной модели
best_parameters = grid_tuning.best_params_
#best_parameters = {'mnb__alpha': 0.575, 'mnb__fit_prior': False, 'tfidf__norm': 'l2', 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': True, 'vect__max_df': 0.1}
plp_final.set_params(**best_parameters)

# Выполним подгонку
plp_final.fit(X_train, y_train)

y_pred_plp1 = plp_final.predict(X_test)
print('F1 score: %f' % f1_score(y_test, y_pred_plp1))

"""Сделаем прогноз и заполним файл согласно задаче"""

# Считываем таблицу в переменную, по которой нужно сделать прогноз
df_pred = pd.read_table('dataset/test.tsv',)
# Выводим 5 строк для проверки
df_pred.head()

# Зададим фичи для прогноза и выполним прогноз
X_pred = df_pred['title']
df_pred['is_fake'] = plp_final.predict(X_pred)
df_pred.head()

# Заполним файл
df_pred.to_csv('dataset/predictions.tsv', index=False, mode='w')